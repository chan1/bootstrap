{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MusicVAE.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["hYaJ6dvF0v7g","R122bwRNbTus","ZLfb2a_12wcj","C_TD5psbv9Ax","moLOftFqBS-0","mDKI2rmOk0Dv","0d4st_BlUBdl"],"toc_visible":true}},"cells":[{"metadata":{"id":"bhOAxQyU0rhs","colab_type":"text"},"cell_type":"markdown","source":["Copyright 2017 Google LLC.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."]},{"metadata":{"id":"hYaJ6dvF0v7g","colab_type":"text"},"cell_type":"markdown","source":["# MusicVAE: A hierarchical recurrent variational autoencoder for music.\n","### ___Adam Roberts and Jesse Engel___\n","\n","MusicVAE learns a latent space of musical sequences, providing different modes\n","of interactive musical creation, including:\n","\n","* Random sampling from the prior distribution.\n","* Interpolation between existing sequences.\n","* Manipulation of existing sequences via a [latent constraint model](https://goo.gl/STGMGx).\n","\n","Examples of these interactions can be generated below, and selections can be heard in our\n","[YouTube playlist](https://www.youtube.com/playlist?list=PLBUMAYA6kvGU8Cgqh709o5SUvo-zHGTxr).\n","\n","For short sequences (e.g., 2-bar \"loops\"), we use a bidirectional LSTM encoder\n","and LSTM decoder. For longer sequences, we use a novel hierarchical LSTM\n","decoder, which helps the model learn longer-term structures.\n","\n","We also model the interdependencies between instruments by training multiple\n","decoders on the lowest-level embeddings of the hierarchical decoder.\n","\n","For additional details, check out the code in our GitHub [repository](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae) and our [paper](https://nips2017creativity.github.io/doc/Hierarchical_Variational_Autoencoders_for_Music.pdf).\n","___\n","\n","This colab notebook is self-contained and should run natively on google cloud. The [code](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae) and [checkpoints](http://download.magenta.tensorflow.org/models/music_vae/checkpoints.tar.gz) can be downloaded separately and run locally, which is required if you want to train your own model."]},{"metadata":{"id":"R122bwRNbTus","colab_type":"text"},"cell_type":"markdown","source":["# Basic Instructions\n","\n","1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n","2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n","3. Listen to the generated samples.\n","4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc.!"]},{"metadata":{"id":"ZLfb2a_12wcj","colab_type":"text"},"cell_type":"markdown","source":["# Environment Setup\n","Includes package installation for sequence synthesis. Will take a few minutes.\n"]},{"metadata":{"id":"PfRDVhNs3UFx","colab_type":"code","colab":{}},"cell_type":"code","source":["import glob\n","\n","print 'Copying checkpoints and example MIDI from GCS. This may take a few minutes...'\n","!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/music_vae/colab/* /content/\n","\n","print 'Installing dependencies...'\n","!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n","!pip install -qU pyfluidsynth pretty_midi\n","\n","if glob.glob('/content/magenta*.whl'):\n","  !pip install -qU /content/magenta*.whl\n","else:\n","  !pip install -qU magenta\n","\n","# Hack to allow python to pick up the newly-installed fluidsynth lib.\n","import ctypes.util\n","def proxy_find_library(lib):\n","  if lib == 'fluidsynth':\n","    return 'libfluidsynth.so.1'\n","  else:\n","    return ctypes.util.find_library(lib)\n","\n","ctypes.util.find_library = proxy_find_library\n","\n","\n","print 'Importing libraries and defining some helper functions...'\n","from google.colab import files\n","import magenta.music as mm\n","from magenta.music.sequences_lib import concatenate_sequences\n","from magenta.models.music_vae import configs\n","from magenta.models.music_vae.trained_model import TrainedModel\n","import numpy as np\n","import os\n","import tensorflow as tf\n","\n","\n","def play(note_sequence):\n","  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n","  \n","def slerp(p0, p1, t):\n","  \"\"\"Spherical linear interpolation.\"\"\"\n","  omega = np.arccos(np.dot(np.squeeze(p0/np.linalg.norm(p0)), np.squeeze(p1/np.linalg.norm(p1))))\n","  so = np.sin(omega)\n","  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n","\n","def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n","                assert_same_length=True, temperature=0.5, \n","                individual_duration=4.0):\n","  \"\"\"Interpolates between a start and end sequence.\"\"\"\n","  _, mu, _ = model.encode([start_seq, end_seq], assert_same_length)\n","  z = np.array([slerp(mu[0], mu[1], t) for t in np.linspace(0, 1, num_steps)])\n","  note_sequences = model.decode(\n","      length=max_length,\n","      z=z,\n","      temperature=temperature)\n","\n","  print 'Start Seq Reconstruction'\n","  play(note_sequences[0])\n","  print 'End Seq Reconstruction'\n","  play(note_sequences[-1])\n","  print 'Mean Sequence'\n","  play(note_sequences[num_steps // 2])\n","  print 'Start -> End Interpolation'\n","  interp_seq = concatenate_sequences(note_sequences, [individual_duration] * len(note_sequences))\n","  play(interp_seq)\n","  mm.plot_sequence(interp_seq)\n","  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n","\n","def download(note_sequence, filename):\n","  mm.sequence_proto_to_midi_file(note_sequence, filename)\n","  files.download(filename)\n","\n","print 'Done'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C_TD5psbv9Ax","colab_type":"text"},"cell_type":"markdown","source":["# 2-Bar Drums Model\n","\n","Below are 4 pre-trained models to experiment with. The first 3 map the 61 MIDI drum \"pitches\" to a reduced set of 9 classes (bass, snare, closed hi-hat, open hi-hat, low tom, mid tom, high tom, crash cymbal, ride cymbal) for a simplified but less expressive output space. The last model uses a [NADE](http://homepages.inf.ed.ac.uk/imurray2/pub/11nade/) to represent all possible MIDI drum \"pitches\".\n","\n","* **drums_2bar_oh_lokl**: This *low* KL model was trained for more *realistic* sampling. The output is a one-hot encoding of 2^9 combinations of hits. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM decoder with 256 nodes in each layer, and a Z with 256 dimensions. During training it was given 0 free bits, and had a fixed beta value of 0.8. After 300k steps, the final accuracy is 0.73 and KL divergence is 11 bits.\n","* **drums_2bar_oh_hikl**: This *high* KL model was trained for *better reconstruction and interpolation*. The output is a one-hot encoding of 2^9 combinations of hits. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM decoder with 256 nodes in each layer, and a Z with 256 dimensions. During training it was given 96 free bits and had a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k, steps the final accuracy is 0.97 and KL divergence is 107 bits.\n","* **drums_2bar_nade_reduced**: This model outputs a multi-label \"pianoroll\" with 9 classes. It has a single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM-NADE decoder with 512 nodes in each layer and 9-dimensional NADE with 128 hidden units, and a Z with 256 dimensions. During training it was given 96 free bits and has a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k steps, the final accuracy is 0.98 and KL divergence is 110 bits.\n","* **drums_2bar_nade_full**:  The output is a multi-label \"pianoroll\" with 61 classes. A single-layer bidirectional LSTM encoder with 512 nodes in each direction, a 2-layer LSTM-NADE decoder with 512 nodes in each layer and 61-dimensional NADE with 128 hidden units, and a Z with 256 dimensions. During training it was given 0 free bits and has a fixed beta value of 0.2. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 300k steps, the final accuracy is 0.90 and KL divergence is 116 bits."]},{"metadata":{"id":"0x8YTRDwv8Gk","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load the pre-trained models.\n","\n","# One-hot encoded.\n","drums_config = configs.CONFIG_MAP['cat-drums_2bar_small']\n","drums_2bar_oh_lokl = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/drums_2bar_small.lokl.ckpt')\n","drums_2bar_oh_hikl = TrainedModel(drums_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/drums_2bar_small.hikl.ckpt')\n","\n","# Multi-label NADE.\n","drums_nade_reduced_config = configs.CONFIG_MAP['nade-drums_2bar_reduced']\n","drums_2bar_nade_reduced = TrainedModel(drums_nade_reduced_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/drums_2bar_nade.reduced.ckpt')\n","drums_nade_full_config = configs.CONFIG_MAP['nade-drums_2bar_full']\n","drums_2bar_nade_full = TrainedModel(drums_nade_full_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/drums_2bar_nade.full.ckpt')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lEJptw-V4CEJ","colab_type":"text"},"cell_type":"markdown","source":["## Generate Samples"]},{"metadata":{"id":"zRUlAshMpDnR","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the prior of the low KL one-hot model.\n","drums_2_ol_samples = drums_2bar_oh_lokl.sample(n=4, length=32, temperature=0.5)\n","for ns in drums_2_ol_samples:\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wIN9qsCwbs2w","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the prior of the high KL one-hot model.\n","for ns in drums_2bar_oh_hikl.sample(n=4, length=32, temperature=0.5):\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pZKXoWpTTw6r","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the prior of the 9-class NADE model.\n","for ns in drums_2bar_nade_reduced.sample(n=4, length=32, temperature=0.5):\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Af3xSi_eT5WX","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the prior of the 61-class NADE model.\n","drums_2_nf_samples = drums_2bar_nade_full.sample(n=4, length=32, temperature=0.5)\n","for ns in drums_2_nf_samples:\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E4bfdQuj4q5h","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download generated samples from the low KL one-hot model.\n","for i, ns in enumerate(drums_2_ol_samples):\n","  download(ns, 'drums_2bar_oh_lokl_sample_%d.mid' % i)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OSwhxkru5mB6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download generated samples from the 61-class NADE model.\n","for i, ns in enumerate(drums_2_nf_samples):\n","  download(ns, 'drums_2bar_nade_full_sample_%d.mid' % i)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RTsrpipz4cFc","colab_type":"text"},"cell_type":"markdown","source":["## Generate Interpolations"]},{"metadata":{"id":"7cnZfjdGwwZg","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use example MIDI files for interpolation endpoints.\n","input_drums_midi_data = [\n","    tf.gfile.Open(fn).read()\n","    for fn in sorted(tf.gfile.Glob('/content/midi/drums_2bar*.mid'))]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yjfyjWPtb8fV","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally upload your own MIDI files to use for interpolation endpoints instead of those provided.\n","input_drums_midi_data = files.upload().values() or input_drums_midi_data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zqCJFtHYb-7A","colab_type":"code","colab":{}},"cell_type":"code","source":["# Extract drums from MIDI files. This will extract all unique 2-bar drum beats\n","# using a sliding window with a stride of 1 bar.\n","drums_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_drums_midi_data]\n","extracted_beats = []\n","for ns in drums_input_seqs:\n","  extracted_beats.extend(drums_nade_full_config.note_sequence_converter.to_notesequences(\n","      drums_nade_full_config.note_sequence_converter.to_tensors(ns)[1]))\n","for i, ns in enumerate(extracted_beats):\n","  print \"Beat\", i\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"facy6uiWcW6l","colab_type":"code","colab":{}},"cell_type":"code","source":["# Select the start and end beat for interpolation.\n","start_beat = extracted_beats[0]\n","end_beat = extracted_beats[1]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MeAboOS1xDgE","colab_type":"code","colab":{}},"cell_type":"code","source":["# Interpolate between beats over 13 steps with \"low\" KL model.\n","# Will not be very accurate and uses a reduced representation.\n","drums_2bar_interp_oh_lokl = interpolate(drums_2bar_oh_lokl, start_beat, end_beat, num_steps=13, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vlQizK6Wcr0c","colab_type":"code","colab":{}},"cell_type":"code","source":["# Interpolate between beats over 13 steps with \"high\" KL model.\n","# Will be much more accurate but uses a reduced represenation.\n","drums_2bar_interp_oh_hikl = interpolate(drums_2bar_oh_hikl, start_beat, end_beat, num_steps=13, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mrb9Qf1YgbB4","colab_type":"code","colab":{}},"cell_type":"code","source":["# Interpolate between beats over 13 steps with the NADE model using the reduced representation.\n","drums_2bar_interp_nade_reduced = interpolate(drums_2bar_nade_reduced, start_beat, end_beat, num_steps=13, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QQzGLCcxglBx","colab_type":"code","colab":{}},"cell_type":"code","source":["# Interpolate between beats over 13 steps with the NADE model using the full representation.\n","drums_2bar_interp_nade_full = interpolate(drums_2bar_nade_full, start_beat, end_beat, num_steps=13, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nkKoQwFEcxpi","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download interpolation MIDI files.\n","download(drums_2bar_interp_oh_lokl, 'drums_2bar_interp_oh_lokl.mid')\n","download(drums_2bar_interp_oh_hikl, 'drums_2bar_interp_oh_hikl.mid')\n","download(drums_2bar_interp_nade_reduced, 'drums_2bar_interp_nade_reduced.mid')\n","download(drums_2bar_interp_nade_full, 'drums_2bar_interp_nade_full.mid')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"moLOftFqBS-0","colab_type":"text"},"cell_type":"markdown","source":["# 2-Bar Melody Model\n","\n","The pre-trained model consists of a single-layer bidirectional LSTM encoder with 2048 nodes in each direction, a 3-layer LSTM decoder with 2048 nodes in each layer, and Z with 512 dimensions. The model was given 0 free bits, and had its beta valued annealed at an exponential rate of 0.99999 from 0 to 0.43 over 200k steps. It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. The final accuracy is 0.95 and KL divergence is 58 bits."]},{"metadata":{"id":"2XCPjwd6BVtm","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load the pre-trained model.\n","mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n","mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/mel_2bar_big.ckpt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wM6gOe6X3hWB","colab_type":"text"},"cell_type":"markdown","source":["## Generate Samples"]},{"metadata":{"id":"RwXUA74cNkh0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the prior.\n","mel_2_samples = mel_2bar.sample(n=4, length=32, temperature=0.5)\n","for ns in mel_2_samples:\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MLg9dQ2D1Xpu","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download samples.\n","for i, ns in enumerate(mel_2_samples):\n","  download(ns, 'mel_2bar_sample_%d.mid' % i)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8YxEHHI937Oa","colab_type":"text"},"cell_type":"markdown","source":["## Generate Interpolations"]},{"metadata":{"id":"H5wCWLMPLfYz","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use example MIDI files for interpolation endpoints.\n","input_mel_midi_data = [\n","    tf.gfile.Open(fn).read()\n","    for fn in sorted(tf.gfile.Glob('/content/midi/mel_2bar*.mid'))]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hu5SeYFnNEe5","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally upload your own MIDI files to use for interpolation endpoints instead of those provided.\n","input_mel_midi_data = files.upload().values() or input_mel_midi_data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xy4vizNUH8GJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Extract melodies from MIDI files. This will extract all unique 2-bar melodies\n","# using a sliding window with a stride of 1 bar.\n","mel_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_mel_midi_data]\n","extracted_mels = []\n","for ns in mel_input_seqs:\n","  extracted_mels.extend(\n","      mel_2bar_config.note_sequence_converter.to_notesequences(\n","          mel_2bar_config.note_sequence_converter.to_tensors(ns)[1]))\n","for i, ns in enumerate(extracted_mels):\n","  print \"Melody\", i\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UL4WG6o6M2S_","colab_type":"code","colab":{}},"cell_type":"code","source":["# Select the start and end melody for interpolation.\n","start_mel = extracted_mels[0]\n","end_mel = extracted_mels[1]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8J4vloU3Pgtz","colab_type":"code","colab":{}},"cell_type":"code","source":["# Interpolate between melodies over 13 steps.\n","mel_2bar_interp = interpolate(mel_2bar, start_mel, end_mel, num_steps=15, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hZVP4JRmTCvB","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download interpolation MIDI file.\n","download(mel_2bar_interp, 'mel_2bar_interp.mid')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mDKI2rmOk0Dv","colab_type":"text"},"cell_type":"markdown","source":["# 16-bar Melody Models\n","\n","The pre-trained hierarchical model consists of a 2-layer stacked bidirectional LSTM encoder with 2048 nodes in each direction for each layer, a 16-step 2-layer LSTM \"conductor\" decoder with 1024 nodes in each layer, a 2-layer LSTM core decoder with 1024 nodes in each layer, and a Z with 512 dimensions. It was given 256 free bits, and had a fixed beta value of 0.2. After 25k steps, the final accuracy is 0.90 and KL divergence is 277 bits."]},{"metadata":{"id":"9zcfdVjjk3Pp","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load the pre-trained models.\n","hierarch_mel_16bar_config = configs.CONFIG_MAP['hiercat-mel_16bar_big']\n","hierarch_mel_16bar = TrainedModel(hierarch_mel_16bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/hiercat_mel_16bar_big.ckpt')\n","\n","flat_mel_16bar_config = configs.CONFIG_MAP['cat-mel_16bar_big']\n","flat_mel_16bar = TrainedModel(flat_mel_16bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/cat_mel_16bar_big.ckpt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l47dxtR82s0t","colab_type":"text"},"cell_type":"markdown","source":["## Generate Samples"]},{"metadata":{"id":"Bptfh7C1njpV","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the hierarchical prior.\n","hmel_16_samples = hierarch_mel_16bar.sample(n=4, length=256, temperature=0.5)\n","for ns in hmel_16_samples:\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eKFK_SR1pL_V","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the flat (baseline) prior.\n","for ns in flat_mel_16bar.sample(n=4, length=256, temperature=0.5):\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X4sDzwq623Ei","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download hierarchical samples.\n","for i, ns in enumerate(hmel_16_samples):\n","  download(ns, 'hierarch_mel_16bar_sample_%d.mid' % i)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_ss6V0582zpU","colab_type":"text"},"cell_type":"markdown","source":["## Generate Means"]},{"metadata":{"id":"38nwpNp_lprY","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use example MIDI files for interpolation endpoints.\n","input_mel_16_midi_data = [\n","    tf.gfile.Open(fn).read()\n","    for fn in sorted(tf.gfile.Glob('/content/midi/mel_16bar*.mid'))]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z-7VjVcPUpHN","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally upload your own MIDI files to use for interpolation endpoints instead of those provided.\n","input_mel_16_midi_data = files.upload().values() or input_mel_16_midi_data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C-WE4Nq2OJxH","colab_type":"code","colab":{}},"cell_type":"code","source":["# Extract melodies from MIDI files. This will extract all unique 16-bar melodies\n","# using a sliding window with a stride of 1 bar.\n","mel_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_mel_16_midi_data]\n","extracted_16_mels = []\n","for ns in mel_input_seqs:\n","  extracted_16_mels.extend(\n","      hierarch_mel_16bar_config.note_sequence_converter.to_notesequences(\n","          hierarch_mel_16bar_config.note_sequence_converter.to_tensors(ns)[1]))\n","for i, ns in enumerate(extracted_16_mels):\n","  print \"Melody\", i\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ySzCC8U2x5g0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Select the start and end melody for interpolation.\n","start_16_mel = extracted_16_mels[0]\n","end_16_mel = extracted_16_mels[1]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u_Xp1rpTrayv","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compute the reconstructions and mean of the two melodies from the hierarchical model.\n","hierarch_mel_16bar_mean = interpolate(hierarch_mel_16bar, start_16_mel, end_16_mel, num_steps=3, max_length=256, individual_duration=32, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w9Dj6FeXpRWz","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compute the reconstructions and mean of the two melodies from the flat (baseline) model.\n","flat_mel_16bar_mean = interpolate(flat_mel_16bar, start_16_mel, end_16_mel, num_steps=3, max_length=256, individual_duration=32, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rONYqtlLkyS2","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download mean MIDI file.\n","download(hierarch_mel_16bar_mean, 'hierarch_mel_16bar_mean.mid')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0d4st_BlUBdl","colab_type":"text"},"cell_type":"markdown","source":["#16-bar \"Trio\" Models (lead, bass, drums)\n","\n","We present two pre-trained models for 16-bar trios: a hierarchical model and a flat (baseline) model.\n","\n","The pre-trained hierarchical model consists of a 2-layer stacked bidirectional LSTM encoder with 2048 nodes in each direction for each layer, a 16-step 2-layer LSTM \"conductor\" decoder with 1024 nodes in each layer, 3 (lead, bass, drums) 2-layer LSTM core decoders with 1024 nodes in each layer, and a Z with 512 dimensions. It was given 1024 free bits, and had a fixed beta value of 0.1.  It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 50k steps, the final accuracy is 0.82 for lead, 0.87 for bass, and 0.90 for drums, and the KL divergence is 1027 bits.\n","\n","The pre-trained flat model consists of a 2-layer stacked bidirectional LSTM encoder with 2048 nodes in each direction for each layer, a 3-layer LSTM decoder with 2048 nodes in each layer, and a Z with 512 dimensions. It was given 1024 free bits, and had a fixed beta value of 0.1.  It was trained with scheduled sampling with an inverse sigmoid schedule and a rate of 1000. After 50k steps, the final accuracy is 0.67 for lead, 0.66 for bass, and 0.79 for drums, and the KL divergence is 1016 bits."]},{"metadata":{"id":"FDW3h0cqUERq","colab_type":"code","colab":{}},"cell_type":"code","source":[" # Load the pre-trained models.\n","hierarch_trio_16bar_config = configs.CONFIG_MAP['hiercat-trio_16bar_big']\n","hierarch_trio_16bar = TrainedModel(hierarch_trio_16bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/hiercat_trio_16bar_big.ckpt')\n","\n","flat_trio_16bar_config = configs.CONFIG_MAP['cat-trio_16bar_big']\n","flat_trio_16bar = TrainedModel(flat_trio_16bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/cat_trio_16bar_big.ckpt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6PxW0_7Z2fvb","colab_type":"text"},"cell_type":"markdown","source":["## Generate Samples"]},{"metadata":{"id":"XKk8rGihUR6B","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the hierarchical model prior.\n","htrio_16_samples = hierarch_trio_16bar.sample(n=4, length=256, temperature=0.5)\n","for ns in htrio_16_samples:\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GSGzPh76XFlv","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate 4 samples from the flat (baseline) model prior.\n","for ns in flat_trio_16bar.sample(n=4, length=256, temperature=0.5):\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fic5W7Z7m7Op","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download hierarchical samples.\n","for i, ns in enumerate(htrio_16_samples):\n","  download(ns, 'hierarch_trio_16bar_sample_%d.mid' % i)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LGIZPuZc2dIa","colab_type":"text"},"cell_type":"markdown","source":["## Generate Means"]},{"metadata":{"id":"3msZzI89UU_F","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use example MIDI files for interpolation endpoints.\n","input_trio_midi_data = [\n","    tf.gfile.Open(fn).read()\n","    for fn in sorted(tf.gfile.Glob('/content/midi/trio_16bar*.mid'))]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9ig0w2cSUs9n","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally upload your own MIDI files to use for interpolation endpoints instead of those provided.\n","input_trio_midi_data = files.upload().values() or input_trio_midi_data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mawDY278UZKY","colab_type":"code","colab":{}},"cell_type":"code","source":["# Extract trios from MIDI files. This will extract all unique 16-bar trios\n","# using a sliding window with a stride of 1 bar.\n","trio_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_trio_midi_data]\n","extracted_trios = []\n","for ns in trio_input_seqs:\n","  extracted_trios.extend(\n","      hierarch_trio_16bar_config.note_sequence_converter.to_notesequences(\n","          hierarch_trio_16bar_config.note_sequence_converter.to_tensors(ns)[1]))\n","for i, ns in enumerate(extracted_trios):\n","  print \"Trio\", i\n","  play(ns)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Plfk8tEkU1nX","colab_type":"code","colab":{}},"cell_type":"code","source":["# Select the start and end trio for interpolation.\n","start_trio = extracted_trios[0]\n","end_trio = extracted_trios[1]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wGpP6frUUxsK","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compute the hierarchical model reconstructions and mean of the two trios.\n","hierarch_trio_16bar_mean = interpolate(hierarch_trio_16bar, start_trio, end_trio, num_steps=3, max_length=256, individual_duration=32, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UQuTQOlZW1LX","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compute the flat (baseline) model reconstructions and mean of the two trios.\n","flat_trio_16bar_mean = interpolate(flat_trio_16bar, start_trio, end_trio, num_steps=3, max_length=256, individual_duration=32, temperature=0.5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bqSklK8CU_cQ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Optionally download mean MIDI file.\n","download(hierarch_trio_16bar_mean, 'hierarch_trio_16bar_mean.mid')"],"execution_count":0,"outputs":[]}]}